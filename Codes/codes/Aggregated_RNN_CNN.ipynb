{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aggregated_RNN_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO-VdRsBu7TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import ast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnU7RbrLvgS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEsB82G0vh-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://stackoverflow.com/a/48438170\n",
        "%cd \"drive/My Drive\"\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0u5zbnHvkty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = os.listdir('patdata')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW42odcXvlNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(columns = ['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'new_label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goFs77eOvmxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = {'Sleep stage W': 0, 'Sleep stage 1': 1, 'Sleep stage 2': 2, 'Sleep stage 3': 3, 'Sleep stage 4': 4, 'Sleep stage R': 5}\n",
        "def literal_return(val):\n",
        "    try:\n",
        "        return ast.literal_eval(val)\n",
        "    except ValueError:\n",
        "        return (val)\n",
        "for file in files:\n",
        "  print(file)\n",
        "  path='patdata/'+file\n",
        "  df_m=pd.read_csv(path)\n",
        "  df_m=pd.read_csv(path,dtype= {\"val1\": object, \"val2\": object, \"val3\": object})\n",
        "  df_m=df_m.rename(columns={\"val1\":'EEG Fpz-Cz',\"val2\":\"EEG Pz-Oz\",\"val3\":\"EOG horizontal\",\"val4\":\"EMG submental\"})\n",
        "  df_m['new_label']=[label_map[x] for x in df_m['labels']]\n",
        "  df_m=df_m[['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'new_label']]\n",
        "  df_m['EEG Fpz-Cz'] = df_m['EEG Fpz-Cz'].apply(literal_return)\n",
        "  df_m['EEG Pz-Oz'] = df_m['EEG Pz-Oz'].apply(literal_return)\n",
        "  #df_m['EEG Fpz-Cz']=[ast.literal_eval(x) for x in df_m['EEG Fpz-Cz']]\n",
        "  #df_m['EEG Pz-Oz']=[ast.literal_eval(x) for x in df_m['EEG Pz-Oz']]\n",
        "  df_m['EOG horizontal']=df_m['EOG horizontal'].apply(literal_return)\n",
        "  df=df.append(df_m)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mljHj_XPvoxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_data11 = list(df['EEG Pz-Oz'])\n",
        "for i in range(len(pred_data11)):\n",
        "  if len(pred_data11[i]) != 300:\n",
        "    pred_data11[i].extend([0.0]*(300-len(pred_data11[i])))\n",
        "pred_data11 = np.asarray(pred_data11)\n",
        "pred_data11.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gShAhJaIwBjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import newaxis\n",
        "pred_data11 = pred_data11[:, newaxis, :]\n",
        "pred_data11.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT8RqzwXwDCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_data12 = list(df['EEG Fpz-Cz'])\n",
        "for i in range(len(pred_data12)):\n",
        "  if len(pred_data12[i]) != 300:\n",
        "    pred_data12[i].extend([0.0]*(300-len(pred_data12[i])))\n",
        "pred_data12 = np.asarray(pred_data12)\n",
        "pred_data12 = pred_data12[:, newaxis, :]\n",
        "pred_data12.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAxYzlflwE1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_data13 = list(df['EOG horizontal'])\n",
        "for i in range(len(pred_data13)):\n",
        "  if len(pred_data13[i]) != 300:\n",
        "    pred_data13[i].extend([0.0]*(300-len(pred_data13[i])))\n",
        "pred_data13 = np.asarray(pred_data13)\n",
        "pred_data13 = pred_data13[:, newaxis, :]\n",
        "pred_data13.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ainZFCkGwGjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_data1 = np.concatenate((np.concatenate((pred_data11, pred_data12),axis = 1), pred_data13),axis = 1)\n",
        "pred_data1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PggIlatjwIbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_data1 = np.array(df['new_label'].values, dtype=int)\n",
        "target_data1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05HWo_AMwKIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(pred_data1, target_data1, test_size=0.3, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EpjqIrJwL5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_train.tofile('x_train.dat')\n",
        "#x_test.tofile('x_test.dat')\n",
        "y_train.tofile('y_train.dat', sep=',')\n",
        "y_test.tofile('y_test.dat', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-LMGB2PwOar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, Dataset\n",
        "import itertools\n",
        "import collections\n",
        "from collections import OrderedDict\n",
        "from tensorflow import feature_column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01mN2r4PwQEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HIOCrSawRrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_train = torch.tensor(x_train.astype(np.float32))\n",
        "#pred_train = torch.from_numpy(x_train)\n",
        "target_train = torch.tensor(y_train)\n",
        "\n",
        "pred_test = torch.tensor(x_test.astype(np.float32))\n",
        "target_test = torch.tensor(y_test)\n",
        "\n",
        "train_data = TensorDataset(pred_train, target_train)\n",
        "test_data = TensorDataset(pred_test, target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_CpaPxUwTPM",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwjeqfu6wU2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "\t\"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.reset()\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.val = 0\n",
        "\t\tself.avg = 0\n",
        "\t\tself.sum = 0\n",
        "\t\tself.count = 0\n",
        "\n",
        "\tdef update(self, val, n=1):\n",
        "\t\tself.val = val\n",
        "\t\tself.sum += val * n\n",
        "\t\tself.count += n\n",
        "\t\tself.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def compute_batch_accuracy(output, target):\n",
        "\t\"\"\"Computes the accuracy for a batch\"\"\"\n",
        "\twith torch.no_grad():\n",
        "\n",
        "\t\tbatch_size = target.size(0)\n",
        "\t\t_, pred = output.max(1)\n",
        "\t\tcorrect = pred.eq(target).sum()\n",
        "\n",
        "\t\treturn correct * 100.0 / batch_size\n",
        "\n",
        "\n",
        "def train(model, device, data_loader, criterion, optimizer, epoch, print_freq=10):\n",
        "\tbatch_time = AverageMeter()\n",
        "\tdata_time = AverageMeter()\n",
        "\tlosses = AverageMeter()\n",
        "\taccuracy = AverageMeter()\n",
        "\n",
        "\tmodel.train()\n",
        "\n",
        "\tend = time.time()\n",
        "\tfor i, (input, target) in enumerate(data_loader):\n",
        "\t\t# measure data loading time\n",
        "\t\tdata_time.update(time.time() - end)\n",
        "\n",
        "\t\tif isinstance(input, tuple):\n",
        "\t\t\tinput = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
        "\t\telse:\n",
        "\t\t\tinput = input.to(device)\n",
        "\t\ttarget = target.to(device)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toutput = model(input)\n",
        "\t\tloss = criterion(output, target)\n",
        "\t\tassert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
        "\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t\t# measure elapsed time\n",
        "\t\tbatch_time.update(time.time() - end)\n",
        "\t\tend = time.time()\n",
        "\n",
        "\t\tlosses.update(loss.item(), target.size(0))\n",
        "\t\taccuracy.update(compute_batch_accuracy(output, target).item(), target.size(0))\n",
        "\n",
        "\t\tif i % print_freq == 0:\n",
        "\t\t\tprint('Epoch: [{0}][{1}/{2}]\\t'\n",
        "\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "\t\t\t\t  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "\t\t\t\t  'Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
        "\t\t\t\tepoch, i, len(data_loader), batch_time=batch_time,\n",
        "\t\t\t\tdata_time=data_time, loss=losses, acc=accuracy))\n",
        "\n",
        "\treturn losses.avg, accuracy.avg\n",
        "\n",
        "\n",
        "def evaluate(model, device, data_loader, criterion, print_freq=10):\n",
        "\tbatch_time = AverageMeter()\n",
        "\tlosses = AverageMeter()\n",
        "\taccuracy = AverageMeter()\n",
        "\n",
        "\tresults = []\n",
        "\n",
        "\tmodel.eval()\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tend = time.time()\n",
        "\t\tfor i, (input, target) in enumerate(data_loader):\n",
        "\n",
        "\t\t\tif isinstance(input, tuple):\n",
        "\t\t\t\tinput = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
        "\t\t\telse:\n",
        "\t\t\t\tinput = input.to(device)\n",
        "\t\t\ttarget = target.to(device)\n",
        "\n",
        "\t\t\toutput = model(input)\n",
        "\t\t\tloss = criterion(output, target)\n",
        "\n",
        "\t\t\t# measure elapsed time\n",
        "\t\t\tbatch_time.update(time.time() - end)\n",
        "\t\t\tend = time.time()\n",
        "\n",
        "\t\t\tlosses.update(loss.item(), target.size(0))\n",
        "\t\t\taccuracy.update(compute_batch_accuracy(output, target).item(), target.size(0))\n",
        "\n",
        "\t\t\ty_true = target.detach().to('cpu').numpy().tolist()\n",
        "\t\t\ty_pred = output.detach().to('cpu').max(1)[1].numpy().tolist()\n",
        "\t\t\tresults.extend(list(zip(y_true, y_pred)))\n",
        "\n",
        "\t\t\tif i % print_freq == 0:\n",
        "\t\t\t\tprint('Test: [{0}/{1}]\\t'\n",
        "\t\t\t\t\t  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "\t\t\t\t\t  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "\t\t\t\t\t  'Accuracy {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
        "\t\t\t\t\ti, len(data_loader), batch_time=batch_time, loss=losses, acc=accuracy))\n",
        "\n",
        "\treturn losses.avg, accuracy.avg, results\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTFqJD7Rwe-m",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBZR5kmwgSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(3,6,5)  #unimproved model <---- change in_channels from 1 to 3\n",
        "        self.conv2 = nn.Conv1d(6,16,5)  #unimproved model\n",
        "        self.rel = nn.ReLU()  #unimproved model\n",
        "        self.max_pool = nn.MaxPool1d(2)  #unimproved model\n",
        "        self.layer1 = nn.Linear(72*16, 128)  #unimproved model\n",
        "        self.layer2 = nn.Linear(128,6)  #unimproved model\n",
        "        self.dropout = nn.Dropout(0.2)  #improved model\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.max_pool(self.rel(self.conv1(x)))  #unimproved model\n",
        "        # x = self.max_pool(self.rel(self.conv2(x)))  #unimproved model\n",
        "        # x = x.view(-1, 656)  #unimproved model\n",
        "        # x = self.rel(self.layer1(x))  #unimproved model\n",
        "        # x = self.layer2(x)  #unimproved model\n",
        "        x = self.max_pool(self.rel(self.dropout(self.conv1(x))))  #improved model\n",
        "        x = self.max_pool(self.rel(self.dropout(self.conv2(x))))  #improved model\n",
        "        x = x.view(-1, 72*16)  #improved model\n",
        "        x = self.rel(self.dropout(self.layer1(x)))  #improved model\n",
        "        x = self.layer2(x)  #improved model\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YpBCnwMwhAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "class MyRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyRNN, self).__init__()\n",
        "        self.rnn = nn.GRU(input_size=300, hidden_size=16,\n",
        "                          num_layers=3, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(in_features=16, out_features=6)\n",
        "        self.rel = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.rel(x[:, -1, :])\n",
        "        # x = self.fc(x[:, -1, :])\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYLF2a8mwlIr",
        "colab_type": "text"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI7dqmXcwjCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# TODO: You can use other packages if you want, e.g., Numpy, Scikit-learn, etc.\n",
        "\n",
        "\n",
        "def plot_learning_curves(train_losses, valid_losses, train_accuracies, valid_accuracies):\n",
        "\t# TODO: Make plots for loss curves and accuracy curves.\n",
        "\t# TODO: You do not have to return the plots.\n",
        "\t# TODO: You can save plots as files by codes here or an interactive way according to your preference.\n",
        "    fig1 = plt.figure()\n",
        "    plt.plot(train_losses, label = \"Training Loss\")\n",
        "    plt.plot(valid_losses, label = \"Validation Loss\")\n",
        "    minposs = valid_losses.index(min(valid_losses))+1 \n",
        "    plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    fig1.suptitle('Loss Curve', fontsize=20)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig('loss_curves.png')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "    fig2 = plt.figure()\n",
        "    plt.plot(train_accuracies, label = \"Training Accuracy\")\n",
        "    plt.plot(valid_accuracies, label = \"Validation Accuracy\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    fig2.suptitle('Accuracy Curve', fontsize=20)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.savefig('accuracy_curves.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(results, class_names):\n",
        "\t# TODO: Make a confusion matrix plot.\n",
        "\t# TODO: You do not have to return the plots.\n",
        "\t# TODO: You can save plots as files by codes here or an interactive way according to your preference.\n",
        "    y_true = [i[0] for i in results]\n",
        "    y_pred = [i[1] for i in results]\n",
        "    C = confusion_matrix(y_true, y_pred)\n",
        "    C1 = np.around(C/C.astype(np.float).sum(axis=1).reshape(C.shape[0],1), decimals=2)\n",
        "    #C2 = pd.DataFrame(C1, range(C.shape[0]), range(C.shape[0]))\n",
        "    #sn.heatmap(C2, annot=True, xticklabels=class_names, yticklabels=class_names)\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(C1)\n",
        "    ax.set_xticks(np.arange(len(class_names)))\n",
        "    ax.set_xticklabels(class_names)\n",
        "    ax.set_yticks(np.arange(len(class_names)))\n",
        "    ax.set_yticklabels(class_names)\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    for i in range(C1.shape[0]):\n",
        "        for j in range(C1.shape[0]):\n",
        "            text = ax.text(j, i, C1[i, j], ha=\"center\", va=\"center\", color=\"w\")\n",
        "    ax.set_title(\"Normalized confusion matrix\")\n",
        "    fig.tight_layout()\n",
        "    plt.savefig('normalized_confusion_matrix.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ESv6ol-wu-m",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JWBkUvuwawI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "NUM_EPOCHS = 40\n",
        "BATCH_SIZE = 32\n",
        "USE_CUDA = False  # Set 'True' if you want to use GPU\n",
        "NUM_WORKERS = 0  # Number of threads used by DataLoader. You can adjust this according to your machine spec.\n",
        "\n",
        "model = MyRNN()\n",
        "#model = RNN()\n",
        "#model = MyRCNN()\n",
        "\n",
        "device = torch.device(\"cuda\" if USE_CUDA and torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(1)\n",
        "if device.type == \"cuda\":\n",
        "\ttorch.backends.cudnn.deterministic = True\n",
        "\ttorch.backends.cudnn.benchmark = False\n",
        "    \n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "valid_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "train_losses, train_accuracies = [], []\n",
        "valid_losses, valid_accuracies = [], []\n",
        "\n",
        "early_stopping = EarlyStopping(patience=20, verbose=True)\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\ttrain_loss, train_accuracy = train(model, device, train_loader, criterion, optimizer, epoch)\n",
        "\tvalid_loss, valid_accuracy, valid_results = evaluate(model, device, valid_loader, criterion)\n",
        "\n",
        "\ttrain_losses.append(train_loss)\n",
        "\tvalid_losses.append(valid_loss)\n",
        "\n",
        "\ttrain_accuracies.append(train_accuracy)\n",
        "\tvalid_accuracies.append(valid_accuracy)\n",
        "\n",
        "\tis_best = valid_accuracy > best_val_acc  # let's keep the model that has the best accuracy, but you can also use another metric.\n",
        "\tif is_best:\n",
        "\t\tbest_val_acc = valid_accuracy\n",
        "\t\t#torch.save(model, os.path.join(PATH_OUTPUT, save_file))\n",
        "\t\tbest_model = model\n",
        "\tearly_stopping(valid_loss, model)\n",
        "\tif early_stopping.early_stop:\n",
        "\t\tprint(\"early Stopping\")\n",
        "\t\tbreak"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2aOmhuGwznn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_learning_curves(train_losses, valid_losses, train_accuracies, valid_accuracies)\n",
        "test_loss, test_accuracy, test_results = evaluate(best_model, device, valid_loader, criterion)\n",
        "\n",
        "class_names = ['Sleep stage W', 'Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R']#, 'Sleep stage ?']\n",
        "#class_names = ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R']\n",
        "plot_confusion_matrix(test_results, class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}